name: Workflow to BigQuery

on:
  schedule:
    - cron: "*/30 * * * *"   # every 30 minutes
  workflow_dispatch:          # allow manual trigger

jobs:
  pipeline:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt google-cloud-bigquery google-cloud-storage elasticsearch requests aiohttp

    # DEBUG: Check if the GCP_SA_KEY secret is available
    - name: Debug check GCP_SA_KEY secret
      run: |
        if [ -z "${{ secrets.GCP_SA_KEY }}" ]; then
          echo "GCP_SA_KEY secret is NOT set!"
          exit 1
        else
          echo "GCP_SA_KEY secret is detected."
          echo "${{ secrets.GCP_SA_KEY }}" | jq 'keys' || echo "Secret present but not valid JSON"
        fi

    # Authenticate with GCP using service account JSON from secrets
    - id: auth
      name: Authenticate to Google Cloud
      if: github.actor != 'dependabot[bot]' && github.event_name != 'pull_request'
      uses: google-github-actions/auth@v2
      with:
        credentials_json: '${{ secrets.GCP_SA_KEY }}'

    # Step 1: Fetch URLs from Elasticsearch
    - name: Run poller (fetch URLs)
      env:
        GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp-key.json
        ES_ENDPOINT: "https://mi-reporting.es.us-west-2.aws.found.io"
        ES_API_KEY_ID: ${{ secrets.ES_API_KEY_ID }}
        ES_API_KEY_SECRET: ${{ secrets.ES_API_KEY_SECRET }}
      run: |
        echo "${{ secrets.GCP_SA_KEY }}" > $GOOGLE_APPLICATION_CREDENTIALS
        python try_new_updates.py

    # Step 2: Download JSON reports
    - name: Download reports
      env:
        GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp-key.json
      run: |
        python token_with_report.py

    # Step 3: Convert JSON → CSV
    - name: Process JSON to CSV
      run: |
        python updating_json_to_new_csv.py

    # Step 4: Append CSV → BigQuery
    - name: Upload to BigQuery
      env:
        GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp-key.json
      run: |
        python upload_to_bigquery.py
